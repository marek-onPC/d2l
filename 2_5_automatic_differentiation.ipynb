{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation\n",
    "\n",
    "Calculating derivatives is the crucial step in all the optimization algorithms that we will use to train deep networks. Modern deep learning frameworks take this work off our plates by offering automatic differentiation (often shortened to autograd).\n",
    "\n",
    "### Exmplanation based on a simple function\n",
    "\n",
    "**y = 2x<sup>T</sup>x**, where **x** is an vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before gradien calculation, we need a place to store it. Because of the calculation complexity in real-life scenarios and how much data needs to be processed and stored - memory management is crucial to not run out of it.\n",
    "For this, gradiend with the respect to vector **x**  we can store **in that vector**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(True)\n",
    "# We can also define this when creating a tensor by x = torch.arange(4.0, requires_grad=True)\n",
    "\n",
    "# Gradient for now is None by default\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use \"matmul\" but the executed algoright vary on the input, while using \"dot\" you specify wich exactly algorimth you want to use\n",
    "# dot product = scalar product (pl. iloczyn skalarny)\n",
    "y = 2 * torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad # Still None\n",
    "y.backward() # Take the gradient of y with respect to x by calling its backward method - \"x\" gradient will be now filled\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient function with respect to the **x** should be:\n",
    "\n",
    "# y' = 2 * (x * x)\n",
    "# (x * x) is essentially (x ** 2)\n",
    "# y' = 2 * (x ** 2)\n",
    "# y' = 4 * x\n",
    "\n",
    "x.grad == 4 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "y.backward()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  5.,  9., 13.])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad \n",
    "# Result - tensor([ 1.,  5.,  9., 13.])\n",
    "# Because PyTorch does NOT automatically resey the gradient buffer.\n",
    "# Instead, the new gradient is added to the already-stored gradient. \n",
    "# This behavior comes in handy when we want to optimize the sum of multiple objective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "y: 6.0\n",
      "x.grad: tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# In order to reset the gradient use \"grad.zero_()\"\n",
    "x.grad.zero_()\n",
    "y = x.sum()\n",
    "y.backward()\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"x.grad: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward for Non-Scalar Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "y: tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)\n",
      "x.grad: tensor([0., 2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "# Just running \"y.backward()\" will result in Error - RuntimeError: grad can be implicitly created only for scalar outputs (for operations that result is a scalar)\n",
    "# By providing gradient you are providing what backward() should compute agains and how gradient resoult should be presented, so \"v * dx * y\", instead of \"dx * y\" by default\n",
    "\n",
    "y.backward(gradient=torch.ones(len(y))) # Faster: y.sum().backward()\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"x.grad: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detaching Computation\n",
    "\n",
    "In order to move some calculations outside of the recorded computational graph - so the calculation will not be included in the grandient, we need to detach the respective computational graph from the final result.\n",
    "\n",
    "Suppose we have **z = x * y** and **y = x * x** but we want to focus on the direct influence of **x** on **z** rather than the influence conveyed via **y**.\n",
    "\n",
    "So we want **x affects z**, NOT **x affects y affects z**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "y: tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)\n",
      "z: tensor([ 0.,  1.,  8., 27.], grad_fn=<MulBackward0>)\n",
      "x.grad: tensor([0., 1., 4., 9.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "\n",
    "y = x * x\n",
    "u = y.detach()\n",
    "# Create a new variable u that takes the same value as y but whose provenance (how it was created) has been wiped out. \n",
    "# Thus u has no ancestors in the graph and gradients do not flow through u to x\n",
    "\n",
    "z = u * x\n",
    "z.sum().backward()\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"z: {z}\")\n",
    "print(f\"x.grad: {x.grad}\")\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "y: tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0., 2., 4., 6.]), tensor([True, True, True, True]))"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Procedure above detaches yâ€™s ancestors from the graph leading to z,\n",
    "# the computational graph leading to y persists and thus we can calculate the gradient of y with respect to x.\n",
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "x.grad, x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor([ 0.,  1.,  8., 27.], grad_fn=<MulBackward0>),\n",
       " tensor([ 0.,  3., 12., 27.]))"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "o = x * x * x\n",
    "o.sum().backward()\n",
    "\n",
    "x, o, x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients and Python Control Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3920, requires_grad=True),\n",
       " tensor(1605.6578, grad_fn=<MulBackward0>),\n",
       " tensor(4096.),\n",
       " tensor(True))"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(a: torch.Tensor):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c\n",
    "\n",
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "\n",
    "a, d, a.grad, a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and exercises\n",
    "\n",
    "For now, try to remember these basics:\n",
    "1. attach gradients to those variables with respect to which we desire derivatives;\n",
    "2. record the computation of the target value;\n",
    "3. execute the backpropagation function;\n",
    "4. and access the resulting gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor(28., grad_fn=<MulBackward0>),\n",
       " tensor([ 0.,  8., 16., 24.]))"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 - running backward() twice result in an error, BUT according to the error message,\n",
    "# you can use retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward\n",
    "x = torch.arange(4.0, requires_grad=True)\n",
    "y = 2 * torch.dot(x, x)\n",
    "y.backward(retain_graph=True)\n",
    "y.backward()\n",
    "x, y, x.grad\n",
    "\n",
    "# Next backpropagation will be calculaten on top of the first result\n",
    "# First calculated grad is - tensor([ 0.,  4.,  8., 12.])\n",
    "# So the second will be calculatedo ntop of that, and result is - tensor([ 0.,  8., 16., 24.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor([   0.,  512., 1024., 1536.], grad_fn=<MulBackward0>),\n",
       " tensor([512., 512., 512., 512.]))"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "def u(a: torch.Tensor):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c\n",
    "\n",
    "a = torch.arange(4.0, requires_grad=True)\n",
    "d = f(a)\n",
    "d.sum().backward()\n",
    "\n",
    "a, d, a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation of what is happening, plus easy-to-understand explanation of gradient by ChatGPT (3.5)\n",
    "\n",
    "\n",
    "**Me:**\n",
    "> a is [0., 1., 2., 3.]\n",
    "> d is [0.,  512., 1024., 1536.]\n",
    "> and gradient is [512., 512., 512., 512.]\n",
    ">\n",
    "> Why gradient for first element is 512 when in both a and d it is 0 so nothing is chaning?\n",
    "\n",
    "**ChatGPT:**\n",
    "> In PyTorch, when you call the `backward()` method on a tensor, it calculates the gradients of that tensor with respect to some scalar value. In your case, you're calling `backward()` on the sum of tensor `d`. This means PyTorch computes the gradient of the sum of `d` with respect to each element of `a`.\n",
    ">\n",
    "> Let's break it down:\n",
    ">\n",
    "> 1. You create tensor `a` with values `[0., 1., 2., 3.]` and `requires_grad=True`, meaning you want to compute gradients with respect to it.\n",
    "> 2. You compute tensor `d` using the function `f(a)`, which involves several operations including multiplication and a loop. The resulting tensor `d` is `[0., 512., 1024., 1536.]`.\n",
    "> 3. You call `d.sum().backward()`, which calculates gradients of the sum of `d` with respect to each element of `a`.\n",
    "> 4. Even though the first element of `a` is 0 and the corresponding element in `d` is also 0, the gradient of the sum of `d` with respect to that element of `a` is still computed. This is because PyTorch calculates the gradient of the sum of `d`, not just the individual elements of `d`.\n",
    "> 5. In this case, the gradient of the sum of `d` with respect to the first element of `a` turns out to be 512, because `d` is calculated based on operations involving `a` and derivatives of those operations.\n",
    ">\n",
    "> So, the gradient for the first element of `a` being 512 indicates how a small change in the first element of `a` affects the overall sum of `d`. It doesn't necessarily mean that the first element of `a` directly influences the first element of `d`. It's more about how changes in `a` affect the output of the entire function `f`.\n",
    "\n",
    "**Me:**\n",
    "> So the gradient is measuring the \"power\" of the change?\n",
    "\n",
    "**ChatGPT:**\n",
    "> Yes, you could think of it that way. The gradient represents the rate of change of the output (in this case, the sum of `d`) with respect to the input (the elements of `a`). \n",
    ">\n",
    "> When you compute gradients in PyTorch, you're essentially asking, \"If I change each element of the input tensor `a` by a small amount, how much will the output change?\" The gradient provides information about the sensitivity of the output to changes in the input.\n",
    ">\n",
    "> In your example, the fact that the gradient for the first element of `a` is 512 means that a small change in the first element of `a` results in a relatively large change in the overall sum of `d`, as compared to changes in the other elements of `a`. So, you could interpret this as indicating the \"power\" or influence of that particular element of `a` on the output of the function `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "# import math\n",
    "\n",
    "# x = torch.rand(size=(), requires_grad=True)\n",
    "# sin_of_x = math.sin(math.radians(90))\n",
    "# sin_of_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
