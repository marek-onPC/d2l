{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation\n",
    "\n",
    "Calculating derivatives is the crucial step in all the optimization algorithms that we will use to train deep networks. Modern deep learning frameworks take this work off our plates by offering automatic differentiation (often shortened to autograd).\n",
    "\n",
    "### Exmplanation based on a simple function\n",
    "\n",
    "**y = 2x<sup>T</sup>x**, where **x** is an vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before gradien calculation, we need a place to store it. Because of the calculation complexity in real-life scenarios and how much data needs to be processed and stored - memory management is crucial to not run out of it.\n",
    "For this, gradiend with the respect to vector **x**  we can store **in that vector**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(True)\n",
    "# We can also define this when creating a tensor by x = torch.arange(4.0, requires_grad=True)\n",
    "\n",
    "# Gradient for now is None by default\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use \"matmul\" but the executed algoright vary on the input, while using \"dot\" you specify wich exactly algorimth you want to use\n",
    "# dot product = scalar product (pl. iloczyn skalarny)\n",
    "y = 2 * torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad # Still None\n",
    "y.backward() # Take the gradient of y with respect to x by calling its backward method - \"x\" gradient will be now filled\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient function with respect to the **x** should be:\n",
    "\n",
    "# y' = 2 * (x * x)\n",
    "# (x * x) is essentially (x ** 2)\n",
    "# y' = 2 * (x ** 2)\n",
    "# y' = 4 * x\n",
    "\n",
    "x.grad == 4 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "y.backward()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  5.,  9., 13.])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad \n",
    "# Result - tensor([ 1.,  5.,  9., 13.])\n",
    "# Because PyTorch does NOT automatically resey the gradient buffer.\n",
    "# Instead, the new gradient is added to the already-stored gradient. \n",
    "# This behavior comes in handy when we want to optimize the sum of multiple objective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "y: 6.0\n",
      "x.grad: tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# In order to reset the gradient use \"grad.zero_()\"\n",
    "x.grad.zero_()\n",
    "y = x.sum()\n",
    "y.backward()\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"x.grad: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward for Non-Scalar Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "y: tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)\n",
      "x.grad: tensor([0., 2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "# Just running \"y.backward()\" will result in Error - RuntimeError: grad can be implicitly created only for scalar outputs (for operations that result is a scalar)\n",
    "# By providing gradient you are providing what backward() should compute agains and how gradient resoult should be presented, so \"v * dx * y\", instead of \"dx * y\" by default\n",
    "\n",
    "y.backward(gradient=torch.ones(len(y))) # Faster: y.sum().backward()\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"x.grad: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detaching Computation\n",
    "\n",
    "In order to move some calculations outside of the recorded computational graph - so the calculation will not be included in the grandient, we need to detach the respective computational graph from the final result.\n",
    "\n",
    "Suppose we have **z = x * y** and **y = x * x** but we want to focus on the direct influence of **x** on **z** rather than the influence conveyed via **y**.\n",
    "\n",
    "So we want **x affects z**, NOT **x affects y affects z**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "y: tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)\n",
      "z: tensor([ 0.,  1.,  8., 27.], grad_fn=<MulBackward0>)\n",
      "x.grad: tensor([0., 1., 4., 9.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "\n",
    "y = x * x\n",
    "u = y.detach()\n",
    "# Create a new variable u that takes the same value as y but whose provenance (how it was created) has been wiped out. \n",
    "# Thus u has no ancestors in the graph and gradients do not flow through u to x\n",
    "\n",
    "z = u * x\n",
    "z.sum().backward()\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"z: {z}\")\n",
    "print(f\"x.grad: {x.grad}\")\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "y: tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0., 2., 4., 6.]), tensor([True, True, True, True]))"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Procedure above detaches yâ€™s ancestors from the graph leading to z,\n",
    "# the computational graph leading to y persists and thus we can calculate the gradient of y with respect to x.\n",
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "x.grad, x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor([ 0.,  1.,  8., 27.], grad_fn=<MulBackward0>),\n",
       " tensor([ 0.,  3., 12., 27.]))"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "o = x * x * x\n",
    "o.sum().backward()\n",
    "\n",
    "x, o, x.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
